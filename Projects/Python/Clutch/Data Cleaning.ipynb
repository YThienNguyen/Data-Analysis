{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from dython import nominal\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "df = pd.read_csv('./Dataset/vehicles.csv')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('filename.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets have a quick look at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can realize some odds based on the data description above. We might need to double check if the vehicle has 3965000 mileage. Moreover, the min price is quite low (at 100), the max price is extremly high (at 1399888). The min passengers is 0, and the max passenger is 17. These points don't make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will drop some columns which we will not use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if id column has only unique values\n",
    "\n",
    "df['id'].nunique() == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if dataset has duplicated rows\n",
    "\n",
    "df.loc[df.duplicated('id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_cols = ['id', 'first_date_seen', 'last_date_seen', 'vin', 'trim', 'description',\n",
    "                    'carfax_url', 'province', 'engine', 'longitude', 'latitude']\n",
    "\n",
    "df.drop(unnecessary_cols, axis = 1, inplace = True)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan is the list of features, have null values\n",
    "\n",
    "Nan = df.isnull().sum()[df.isnull().sum() > 0]\n",
    "\n",
    "Nan.sort_values().plot(kind = 'barh', figsize = (8, 8), color = \"#3F5D7D\");\n",
    "\n",
    "for y, x in enumerate(Nan.sort_values()):\n",
    "    \n",
    "    plt.annotate(str(round(x/df.shape[0]*100,2))+'%', xy=(x, y), size=10)\n",
    "    \n",
    "plt.xlabel('The Number of Missing Values')\n",
    "\n",
    "plt.ylabel('Feature Names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Null rows in some columns\n",
    "\n",
    "df.dropna(subset = ['color', 'price', 'seller_name', 'mileage'], inplace = True)\n",
    "\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to check if two categorical columns are correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_categorical_correlated(col1, col2):\n",
    "    \n",
    "    tmp_crosstab = pd.crosstab(index = df[col1], columns = df[col2])\n",
    "    \n",
    "    tmp_crosstab_result = chi2_contingency(tmp_crosstab)\n",
    "    \n",
    "    if round(tmp_crosstab_result[1], 2) < 0.05:\n",
    "        \n",
    "        result = col1 + ' and ' + col2 + ' are correlated'\n",
    "        \n",
    "        # Set missing values to the most occurrence of its corresponding correlated column\n",
    "        \n",
    "        for i in range(len(df.year)):\n",
    "\n",
    "            if (pd.isnull(df[col1][i])) | (df[col1][i] == 0):\n",
    "\n",
    "                if df[col2][i] in tmp_crosstab.columns.tolist():\n",
    "\n",
    "                    df.loc[i, col1] = tmp_crosstab[df[col2][i]].idxmax()    \n",
    "\n",
    "        # Double-check if there are null values in body_type column\n",
    "\n",
    "        df_tmp = df.loc[df['body_type'].isnull()]\n",
    "\n",
    "        if df_tmp.shape[0] < 2500:\n",
    "\n",
    "            # Dropping those rows\n",
    "\n",
    "            df.dropna(subset = [col1], inplace = True)\n",
    "\n",
    "            df.reset_index(drop = True, inplace = True)                    \n",
    "                    \n",
    "    else:\n",
    "        \n",
    "        result = col1 + ' and ' + col2 + ' are not correlated'\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship between model and body_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_categorical_correlated('body_type', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check again\n",
    "\n",
    "df['body_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship between passengers and body_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_categorical_correlated('passengers', 'body_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check again\n",
    "\n",
    "df['passengers'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see what type of car has 17 passenger seats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['passengers'] == 17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not make sense that Crosstrek has 17 seats. Thereby, we will drop this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df['passengers'] == 17].index, inplace = True)\n",
    "\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Double-check passengers column again\n",
    "\n",
    "df['passengers'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will do some transformation to make data more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing any whitespaces in the beginning and ending of a string\n",
    "# Titling strings\n",
    "# Upper-case names\n",
    "\n",
    "for col in ['model', 'color', 'fuel_type', 'seller_name']:\n",
    "    \n",
    "    df[col] = df[col].apply(lambda row: row.rstrip().lstrip().title() if not pd.isnull(row) else row)\n",
    "    \n",
    "for col in ['make', 'body_type', 'city']:\n",
    "    \n",
    "    df[col] = df[col].apply(lambda row: row.rstrip().lstrip().upper() if not pd.isnull(row) else row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing data in some columns for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['drivetrain'] = df['drivetrain'].apply(lambda x: x.replace('4x4', 'AWD').replace('4WD', 'AWD').replace('2WD', 'FWD').replace('4X4', 'AWD') if not pd.isnull(x) else x)\n",
    "\n",
    "# Double-check drivetrain column again\n",
    "\n",
    "df['drivetrain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.year)):\n",
    "    \n",
    "    if not pd.isnull(df['transmission'][i]):\n",
    "    \n",
    "        if 'Automatic' in df['transmission'][i]:\n",
    "\n",
    "            df.loc[i, 'transmission'] = 'Automatic'\n",
    "\n",
    "        elif 'Manual' in df['transmission'][i]:\n",
    "\n",
    "            df.loc[i, 'transmission'] = 'Manual'\n",
    "\n",
    "        elif 'CVT' in df['transmission'][i]:\n",
    "\n",
    "            df.loc[i, 'transmission'] = 'CVT'   \n",
    "        \n",
    "# Double-check transmission column again\n",
    "\n",
    "df['transmission'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuel_type column\n",
    "\n",
    "df['fuel_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell \"Flexible\", \"Other\", and \"Other/Don't Know\" are noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['fuel_type'].isin([\"Flexible\", \"Other\", \"Other/Don’T Know\"])].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove those rows because the number of rows is not high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df['fuel_type'].isin([\"Flexible\", \"Other\", \"Other/Don’T Know\"])].index, inplace=True)\n",
    "\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Double-check fuel_type column again\n",
    "\n",
    "df['fuel_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship between model and drivetrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_categorical_correlated('drivetrain', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check again\n",
    "\n",
    "df['drivetrain'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship between model and drivetrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_categorical_correlated('transmission', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check again\n",
    "\n",
    "df['transmission'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship between model and fuel_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_categorical_correlated('fuel_type', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check again\n",
    "\n",
    "df['fuel_type'] = df['fuel_type'].apply(lambda x: x.replace('Gasoline', 'Gas').replace('Gas Fuel', 'Gas').replace('Gas - Hybrid', 'Gas Hybrid'))\n",
    "\n",
    "df['fuel_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert boolean values in is_private column to a column of integers 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_private'] = df['is_private'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check again\n",
    "\n",
    "df['is_private'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are no null values in all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid Original Equipment Manufacturers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['make'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year has no significance on its own. Thus, we need to extract how old a car is and see how its price might be affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many years old the car is.\n",
    "\n",
    "df['car_age'] = 2022 - df['year']\n",
    "\n",
    "# Drop the year column\n",
    "\n",
    "df.drop(['year'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's go back to the odds which found in previous data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a function to remove all outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_points(col):\n",
    "    \n",
    "    data = sorted(df[col].unique().tolist())\n",
    "    \n",
    "    # Calculate first(q1) and third quartile(q3)\n",
    "    \n",
    "    q1, q3 = np.percentile(data, [25,75])\n",
    "    \n",
    "    # Find interquartile range (q3-q1)\n",
    "    \n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    lower_bound = q1 - (1.5 * q1)\n",
    "    \n",
    "    upper_bound = q3 + (1.5 * q3)\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = outlier_points('mileage')\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop all outliers for mileage column\n",
    "\n",
    "df.drop(df.loc[(df['mileage'] < x) | (df['mileage'] > y)].index, inplace = True)\n",
    "\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = outlier_points('price')\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all outliers for price column\n",
    "\n",
    "df.drop(df.loc[(df['price'] < a) | (df['price'] > b)].index, inplace = True)\n",
    "\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, d = outlier_points('car_age')\n",
    "\n",
    "print(c)\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all outliers for car_age column\n",
    "\n",
    "df.drop(df.loc[(df['car_age'] < c) | (df['car_age'] > d)].index, inplace = True)\n",
    "\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a quick look at data description again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "\n",
    "sns.distplot(df['price'], color = \"#3F5D7D\")\n",
    "\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.title(\"Distribution of the variable 'price'\")\n",
    "\n",
    "plt.axvline(df['price'].mean(), linestyle = '--', color = 'r', label = 'mean')\n",
    "\n",
    "plt.axvline(df['price'].median(), linestyle = '--', color = 'b', label = 'median')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % df['price'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of prices shows a high positive skewness to the left (skew > 1). The issue might be in regards to homoscedasticity and assumption violations. Log(price) would be a good solution to have a more visualization of the distribution of the price. Moreover, log(price) has no negative side effects on the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = np.log(df['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will save down the cleaned file for future uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./Dataset/vehicles-cleaned.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
